{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f100322a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dust.process_data_dust import determine_units\n",
    "import xarray as xr\n",
    "import dust\n",
    "from dask.distributed import Client, LocalCluster\n",
    "from dask_jobqueue import SLURMCluster\n",
    "import dask\n",
    "import numpy as np\n",
    "from netCDF4 import date2num, num2date\n",
    "import pandas as pd\n",
    "import time\n",
    "import sys\n",
    "from dask.diagnostics import ProgressBar\n",
    "import numpy\n",
    "import zarr\n",
    "from numcodecs import Blosc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427cfac4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def setup_outda(ds, x0, x1, y0, y1, kind=None):\n",
    "    \"\"\"\n",
    "    DESCRIPTION:\n",
    "    ===========\n",
    "        Setup output dataset for storing processes flexpart output\n",
    "    ARGUMENTS:\n",
    "    ==========\n",
    "        dset: xarray.dataset\n",
    "            dataset containing FLEXPART model output\n",
    "        x0: float\n",
    "            lon of lower left corner of cutout.\n",
    "        x1: float\n",
    "            longtude of upper right corner of cutout.\n",
    "        y0: float\n",
    "            latitude of lower left corner of cutout.\n",
    "        y1: float\n",
    "            latidue of upper left corner of cutout.\n",
    "\n",
    "    RETURN:\n",
    "    =======\n",
    "        out_data: empty output DataArray.\n",
    "    \"\"\"\n",
    "\n",
    "    # select output domain\n",
    "    dset = ds.sel(lon=slice(x0, x1), lat=slice(y0, y1))\n",
    "\n",
    "    # Assumes that the first part of the RELCOM string contains the date.\n",
    "    if isinstance(dset.RELCOM.values[0], np.bytes_):\n",
    "        dset = dset.assign(RELCOM=dset.RELCOM.astype(str))\n",
    "\n",
    "    # Determine size of backward time dimmension\n",
    "    lout_step = abs(dset.attrs[\"loutstep\"])\n",
    "    btime_size = int(dset[\"LAGE\"] / lout_step * 1e-9)\n",
    "    lout_step_h = int(lout_step / (60 * 60))\n",
    "    btime_array = -np.arange(\n",
    "        lout_step_h, btime_size * lout_step_h + lout_step_h, lout_step_h\n",
    "    )\n",
    "    # Create new time forward time dimmension\n",
    "    t0 = pd.to_datetime(dset.ibdate + dset.ibtime) + pd.to_timedelta(\n",
    "        dset[\"LAGE\"].values, unit=\"ns\"\n",
    "    )\n",
    "    t0=t0.to_pydatetime()[0]\n",
    "    # Assumes that the first part of the RELCOM string contains the date.\n",
    "    time_a = pd.to_datetime(\n",
    "        [date.split(\" \")[0] for date in dset.RELCOM.values], format=\"%Y%m%d%H\"\n",
    "    ).to_pydatetime()\n",
    "    \n",
    "    time_a = date2num(\n",
    "        time_a, units=\"hours since {}\".format(t0.strftime(\"%Y-%m-%d %H:%S\"))\n",
    "    )\n",
    "    \n",
    "    time_var = xr.Variable(\n",
    "        \"time\",\n",
    "        time_a,\n",
    "        attrs=dict(\n",
    "            units=\"hours since {}\".format(t0.strftime(\"%Y-%m-%d %H:%M:%S\")),\n",
    "            calendar=\"proleptic_gregorian\",\n",
    "        ),\n",
    "    )\n",
    "    # create output DataArray\n",
    "    out_data = xr.DataArray(\n",
    "        np.zeros(\n",
    "            (len(dset[\"pointspec\"]), btime_size, len(dset[\"lat\"]), len(dset[\"lon\"])),\n",
    "            dtype=np.float32,\n",
    "        ),\n",
    "        dims=[\"time\", \"btime\", \"lat\", \"lon\"],\n",
    "        coords={\n",
    "            \"time\": time_var,\n",
    "            \"btime\": (\n",
    "                \"btime\",\n",
    "                btime_array,\n",
    "                dict(long_name=\"time along back trajectory\", units=\"hours\"),\n",
    "            ),\n",
    "            \"lon\": (\"lon\", dset[\"spec001_mr\"].lon.data, dset.lon.attrs),\n",
    "            \"lat\": (\"lat\", dset[\"spec001_mr\"].lat.data, dset.lat.attrs),\n",
    "        },\n",
    "        attrs=dict(\n",
    "            spec_com=dset.spec001_mr.attrs[\"long_name\"],\n",
    "        ),\n",
    "    )\n",
    "    # print(scale_factor)\n",
    "    last_btime = out_data.btime[-1].values\n",
    "    first_btime = out_data.btime[0].values\n",
    "    time_units = out_data.time.units\n",
    "    if kind:\n",
    "        out_data.name = kind\n",
    "    return out_data\n",
    "\n",
    "def reorder_da(da,ems_sens, groups):\n",
    "    pspec = groups[da.time.values] # get spec that I want\n",
    "    ems_sens = ems_sens[pspec]\n",
    "    date0 = da.time.values + da.btime[0].values\n",
    "    date1 =da.time.values + da.btime[-1].values\n",
    "    ems_sens = ems_sens.sel(time=slice(date1, date0))\n",
    "    ems_sens = ems_sens.rename(time=\"btime\")\n",
    "    da = ems_sens[::-1].assign_coords(btime=da.btime)\n",
    "    return da\n",
    "\n",
    "def calc_source_contrib(da, ds_ems, scale_factor):\n",
    "    date0 = da.time.values + da.btime[0].values\n",
    "    date1 =da.time.values + da.btime[-1].values\n",
    "\n",
    "    ds_ems = ds_ems.sel(time=da.time+da.btime)\n",
    "    \n",
    "    source_contrib = da*ds_ems*scale_factor\n",
    "    \n",
    "    return source_contrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921cd1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = snakemake.params\n",
    "x0 = params.x0\n",
    "x1 = params.x1\n",
    "y0 = params.y0\n",
    "y1 = params.y1\n",
    "height = params.get('height',100)\n",
    "use_dask = params.get('use_dask',True)\n",
    "use_Slurm = params.get('use_slurm', False)\n",
    "kind = snakemake.wildcards.kind\n",
    "if use_dask:\n",
    "    dask.config.set({'distributed.worker.memory.spill':0.85,\n",
    "                    'distributed.worker.memory.pause':0.9,\n",
    "                    'distributed.worker.memory.target':0.95})\n",
    "    \n",
    "    if use_Slurm:\n",
    "        res = snakemake.resources\n",
    "        cluster = SLURMCluster(account=\"nn2806k\",cores=1, memory=res.memory_per_job,\n",
    "                      walltime=res.time, interface='ib0',\n",
    "                      scheduler_options={'dashboard_address':None})\n",
    "        cluster.adapt(maximum_jobs=res.max_threads)\n",
    "    else:\n",
    "        cluster = LocalCluster(n_workers=snakemake.threads,\n",
    "                       threads_per_worker=1,\n",
    "                       memory_limit='16GB'\n",
    "                       )\n",
    "    client = Client(cluster)\n",
    "\n",
    "flexdust_dict = dust.read_flexdust_output(snakemake.input.flexdust_path+'/')\n",
    "flexdust_ds = flexdust_dict['dset'].sel(lon=slice(x0,x1), lat=slice(y0,y1))\n",
    "attrsfd = flexdust_dict['Summary']\n",
    "attrsfd.pop('Corr. land/sea')\n",
    "ds = xr.open_dataset(snakemake.input.flexpart_path[0]).sel(longitude=slice(x0,x1), latitude=slice(y0,y1))\n",
    "ds = ds.chunk({'pointspec':1})\n",
    "ds = ds.rename_dims({'longitude':'lon','latitude':'lat'})\n",
    "ds = ds.rename_vars({'longitude':'lon','latitude':'lat'})\n",
    "\n",
    "out_da = setup_outda(ds, x0,x1,y0,y1,kind)\n",
    "out_da = out_da.to_dataset()\n",
    "out_da = out_da.assign(surface_sensitivity=setup_outda(ds,x0,x1,y0,y1,kind='surface_sensitivity'))\n",
    "out_da = xr.decode_cf(out_da).chunk({'time':1})\n",
    "\n",
    "flexdust_ds = flexdust_ds.interp_like(out_da.isel(time=0))\n",
    "lout_step = abs(ds.attrs[\"loutstep\"])\n",
    "ind_receptor = ds.ind_receptor \n",
    "if ind_receptor == 3 or ind_receptor == 4:\n",
    "    scale_factor = (1 / (height)) * 1000  # Deposition is accumulative\n",
    "else:\n",
    "    # Concentration is not  accumulative Units of FLEXDUST need to be g/m^3s\n",
    "    scale_factor = (1 / (height * lout_step)) * 1000\n",
    "\n",
    "f_name, field_unit, sens_unit, field_name = determine_units(ind_receptor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cb40e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "da = ds.spec001_mr\n",
    "\n",
    "da = da.squeeze().sortby('time')\n",
    "\n",
    "grb=out_da['surface_sensitivity'].groupby('time')\n",
    "\n",
    "out_da = out_da.assign(surface_sensitivity=grb.map(reorder_da,args=[da.groupby('pointspec'),grb.groups]))\n",
    "\n",
    "grb=out_da['surface_sensitivity'].groupby('time')\n",
    "\n",
    "out_da=out_da.assign({kind:grb.map(calc_source_contrib, args=[flexdust_ds['Emission'], scale_factor])})\n",
    "out_da = out_da.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565c055b",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_da = out_da.assign(\n",
    "    {\n",
    "        \"RELLAT1\": ds[\"RELLAT1\"][0],\n",
    "        \"RELLNG1\": ds[\"RELLNG1\"][0],\n",
    "        \"RELZ1\": ds[\"RELZZ1\"][0],\n",
    "        \"RELZ2\": ds[\"RELZZ2\"][0],\n",
    "        \"RELPART\": ds[\"RELPART\"].sum(keep_attrs=True),\n",
    "    }\n",
    ")\n",
    "\n",
    "# dset.attrs[\"ibdate\"] = t0.strftime(\"%Y%m%d\")\n",
    "# dset.attrs[\"ibtime\"] = t0.strftime(\"%H%M%S\")\n",
    "# out_da['surface_sensitivity'].attrs = {}\n",
    "# out_da[kind].attrs = {}\n",
    "out_da.attrs=ds.attrs.copy()\n",
    "relcom_str= str(ds.RELCOM[0].values.astype('U35')).strip().split(' ',2)[1:]\n",
    "out_da.attrs['relcom']=[s.strip() for s in relcom_str]\n",
    "# out_da.attrs[\"relcom\"] = receptor_name\n",
    "\n",
    "out_da[kind].attrs[\"units\"] = field_unit\n",
    "out_da[kind].attrs[\"long_name\"] = field_name\n",
    "out_da[\"surface_sensitivity\"].attrs[\"units\"] = sens_unit\n",
    "\n",
    "out_da.attrs[\"title\"] = \"FLEXPART/FLEXDUST model output\"\n",
    "out_da.attrs[\n",
    "    \"references\"\n",
    "] = \"https://doi.org/10.5194/gmd-12-4955-2019, https://doi.org/10.1002/2016JD025482\"\n",
    "out_da.attrs[\"history\"] = (\n",
    "    \"{} processed by {}, \".format(time.ctime(time.time()), snakemake.rule)\n",
    "    + out_da.attrs[\"history\"]\n",
    ")\n",
    "out_da.attrs['filename'] = snakemake.output.outpath.split('/')[-1]\n",
    "out_da.attrs = {**out_da.attrs,**attrsfd}\n",
    "out_da.attrs['varName'] = kind\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce4d5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_py(attrs):\n",
    "    out_at = {}\n",
    "    for at in attrs:\n",
    "            \n",
    "        if len(at.split(' ')) > 1:\n",
    "            k = \"_\".join(at.split(' '))\n",
    "        else:\n",
    "            k = at\n",
    "        \n",
    "    #     print(type(out_da.attrs[at]))\n",
    "        if isinstance(attrs[at],numpy.float32):\n",
    "            out_at[k]= str(attrs[at])\n",
    "        elif isinstance(attrs[at],numpy.int32):\n",
    "            out_at[k] = str(attrs[at])\n",
    "#             print(type(out_da.attrs[at]))\n",
    "        else:\n",
    "            out_at[k] = attrs[at]\n",
    "    return out_at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d547f613",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_da.attrs = convert_to_py(out_da.attrs)\n",
    "out_da['btime'].attrs = convert_to_py(out_da['btime'].attrs)\n",
    "out_da['lon'].attrs = convert_to_py(out_da['lon'].attrs)\n",
    "out_da['lat'].attrs = convert_to_py(out_da['lat'].attrs)\n",
    "# out_da['surface_sensitivity'].attrs = {}\n",
    "# out_da[kind].attrs = {}\n",
    "# out_da.attrs = {}\n",
    "\n",
    "encoding={'zlib':True, 'complevel':7, \n",
    "    'fletcher32' : False,'contiguous': False, 'shuffle' : True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce86040",
   "metadata": {},
   "outputs": [],
   "source": [
    "snakemake.output.outpath.endswith('nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d29b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if snakemake.output.outpath.endswith('zarr'):\n",
    "\n",
    "    zarr.storage.default_compressor = Blosc(cname='lz4', clevel=7, shuffle=1, blocksize=0)\n",
    "    outfile = out_da.to_zarr(snakemake.output.outpath,mode='w', consolidated=True, compute=False)\n",
    "else:\n",
    "    outfile = out_da.to_netcdf(snakemake.output.outpath, compute=False,encoding={kind:encoding,'surface_sensitivity': encoding},\n",
    "                            unlimited_dims=['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14956bec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with ProgressBar():\n",
    "    result=outfile.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfca922",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 | packaged by conda-forge | (main, Nov 22 2022, 08:26:04) [GCC 10.4.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "b9eb251bb09e6c3e3904ff66039a503c2eef0c1fb535124cffa63ac82b6607a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
